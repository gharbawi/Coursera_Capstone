{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n",
    "soup= BeautifulSoup(source,'lxml')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Beatifulsoup liberary to get table from Wiki website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1A</td>\n",
       "      <td>Not assigned</td>\n",
       "      <td>Not assigned\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2A</td>\n",
       "      <td>Not assigned</td>\n",
       "      <td>Not assigned\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Parkwoods\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Victoria Village\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode       Borough        Neighborhood\n",
       "0     None          None                None\n",
       "1      M1A  Not assigned      Not assigned\\n\n",
       "2      M2A  Not assigned      Not assigned\\n\n",
       "3      M3A    North York         Parkwoods\\n\n",
       "4      M4A    North York  Victoria Village\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(source,'lxml')\n",
    "table = soup.find('div', class_=\"mw-parser-output\").table\n",
    "table_rows = table.find_all('tr')\n",
    "l=[]\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "#     print(td)\n",
    "    row = [tr.text for tr in td]\n",
    "#     print(row)\n",
    "    l.append(row)\n",
    "table_=pd.DataFrame(l, columns=[\"Postcode\", \"Borough\",\"Neighborhood\"])\n",
    "df=table_\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start edit the table to get the target assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M3A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Parkwoods,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M4A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Victoria Village,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M5A</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Harbourfront,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M5A</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Regent Park,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M6A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Lawrence Heights,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode           Borough       Neighborhood\n",
       "0      M3A        North York         Parkwoods,\n",
       "1      M4A        North York  Victoria Village,\n",
       "2      M5A  Downtown Toronto      Harbourfront,\n",
       "3      M5A  Downtown Toronto       Regent Park,\n",
       "4      M6A        North York  Lawrence Heights,"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_=df[df['Borough']!='Not assigned']\n",
    "df_.drop(df_.index[0],inplace= True)\n",
    "df_.reset_index(drop=True,inplace=True)\n",
    "df_ = df_.replace('\\n',',', regex=True)\n",
    "df_['Neighborhood'] = np.where(df_['Neighborhood'] == \"Not assigned,\", df_['Borough']+\",\", df_['Neighborhood'])\n",
    "df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_comma(x):\n",
    "    y=x[:-1]\n",
    "    return y   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step to get Datafarame and shape target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1B</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Rouge,Malvern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1C</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Highland Creek,Rouge Hill,Port Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1E</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Guildwood,Morningside,West Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1G</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Woburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1H</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Cedarbrae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode      Borough                          Neighborhood\n",
       "0      M1B  Scarborough                         Rouge,Malvern\n",
       "1      M1C  Scarborough  Highland Creek,Rouge Hill,Port Union\n",
       "2      M1E  Scarborough       Guildwood,Morningside,West Hill\n",
       "3      M1G  Scarborough                                Woburn\n",
       "4      M1H  Scarborough                             Cedarbrae"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=df_.groupby('Postcode')['Borough'].first()\n",
    "B=df_.groupby('Postcode')['Neighborhood'].sum().apply(lambda x: insert_comma(x))\n",
    "dataframe=pd.DataFrame([A,B]).transpose().reset_index()\n",
    "dataframe.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe['Postcode'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geocoder # import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe['latitude']=None\n",
    "# dataframe['longitude']=None\n",
    "\n",
    "# for postal_code in dataframe['Postcode']:\n",
    "# # initialize your variable to None\n",
    "#     lat_lng_coords = None\n",
    "# # loop until you get the coordinates\n",
    "#     while(lat_lng_coords is None):\n",
    "#         print(postal_code)\n",
    "#         g = geocoder.google('{}, Toronto, Ontario'.format(postal_code))\n",
    "#         lat_lng_coords = g.latlng\n",
    "#         print('NA')\n",
    "    \n",
    "#     print(postal_code)\n",
    "\n",
    "#     dataframe['latitude'].append(lat_lng_coords[0])\n",
    "#     dataframe['latitude'].append(lat_lng_coords[1])\n",
    "#doesnt work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start read CSV file to get the Lat and Long for Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\HP\\\\Desktop\\\\projects\\\\Coursera_Capstone\\\\Geospatial_Coordinates.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-aba576af1519>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\HP\\Desktop\\projects\\Coursera_Capstone\\Geospatial_Coordinates.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\HP\\\\Desktop\\\\projects\\\\Coursera_Capstone\\\\Geospatial_Coordinates.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv (r'C:\\Users\\HP\\Desktop\\projects\\Coursera_Capstone\\Geospatial_Coordinates.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two Dataframe to get the required target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.merge(df, dataframe, left_on='Postal Code', right_on='Postcode')\n",
    "data_frame=data_frame[['Postcode','Borough','Neighborhood','Latitude','Longitude']]\n",
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "# !conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# !conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the steps of clustering Toronto neighborhood as Newyork example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Toronto, Ontario'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"my_application\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Toronto using latitude and longitude values\n",
    "map_Toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(data_frame['Latitude'], data_frame['Longitude'], data_frame['Borough'], data_frame['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_Toronto)  \n",
    "    \n",
    "map_Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'SYNKAEL54LI1HUIAAZJ5VCZT3OISLVZSEAAASQDTUWRCXAVN' # your Foursquare ID\n",
    "CLIENT_SECRET = 'JSJZWCJ3LNYT0YLLWXZKXXBFZ3JMJGYPX420H2AMWAQJF55K' # your Foursquare Secret\n",
    "VERSION = '20140715' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT=200\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=1000):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "#         print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "#         print(venues_list)\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    " \n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "#     print(nearby_venues.head(2))\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_venues = getNearbyVenues(names=data_frame['Neighborhood'],latitudes=data_frame['Latitude'],longitudes=data_frame['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_venues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_venues.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Toronto_onehot = pd.get_dummies(Toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "\n",
    "# # add neighborhood column back to dataframe\n",
    "Toronto_onehot['Neighborhood'] = Toronto_venues['Neighborhood'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_onehot.head(5)\n",
    "Toronto_onehot.columns.values\n",
    "Toronto_onehot = Toronto_onehot[['Neighborhood' ,'Accessories Store', 'Afghan Restaurant', 'African Restaurant',\n",
    "       'Airport', 'Airport Lounge', 'American Restaurant', 'Amphitheater',\n",
    "       'Animal Shelter', 'Antique Shop', 'Aquarium', 'Art Gallery',\n",
    "       'Art Museum', 'Arts & Crafts Store', 'Asian Restaurant',\n",
    "       'Athletics & Sports', 'Auto Dealership', 'Auto Garage',\n",
    "       'Automotive Shop', 'BBQ Joint', 'Baby Store', 'Badminton Court',\n",
    "       'Bagel Shop', 'Bakery', 'Bank', 'Bar', 'Baseball Field',\n",
    "       'Baseball Stadium', 'Basketball Stadium', 'Beach', 'Beach Bar',\n",
    "       'Beer Bar', 'Beer Store', 'Belgian Restaurant', 'Bike Shop',\n",
    "       'Bistro', 'Bookstore', 'Boutique', 'Bowling Alley',\n",
    "       'Brazilian Restaurant', 'Breakfast Spot', 'Brewery', 'Bridal Shop',\n",
    "       'Bridge', 'Bubble Tea Shop', 'Buffet', 'Building', 'Burger Joint',\n",
    "       'Burrito Place', 'Bus Line', 'Bus Station', 'Bus Stop',\n",
    "       'Business Service', 'Butcher', 'Cafeteria', 'Caf√©',\n",
    "       'Cajun / Creole Restaurant', 'Camera Store', 'Candy Store',\n",
    "       'Cantonese Restaurant', 'Caribbean Restaurant', 'Castle',\n",
    "       'Cemetery', 'Cheese Shop', 'Chinese Restaurant', 'Chiropractor',\n",
    "       'Chocolate Shop', 'Church', 'Churrascaria', 'Climbing Gym',\n",
    "       'Clothing Store', 'Cocktail Bar', 'Coffee Shop', 'College Gym',\n",
    "       'College Lab', 'College Quad', 'College Rec Center',\n",
    "       'College Stadium', 'College Theater', 'Comedy Club',\n",
    "       'Comfort Food Restaurant', 'Comic Shop', 'Community Center',\n",
    "       'Concert Hall', 'Construction & Landscaping', 'Convenience Store',\n",
    "       'Cosmetics Shop', 'Coworking Space', 'Creperie',\n",
    "       'Cuban Restaurant', 'Cupcake Shop', 'Curling Ice', 'Dance Studio',\n",
    "       'Deli / Bodega', 'Department Store', 'Design Studio',\n",
    "       'Dessert Shop', 'Dim Sum Restaurant', 'Diner', 'Discount Store',\n",
    "       'Dive Bar', 'Dog Run', 'Doner Restaurant', 'Donut Shop',\n",
    "       'Dumpling Restaurant', 'Eastern European Restaurant',\n",
    "       'Electronics Store', 'Empanada Restaurant', 'Ethiopian Restaurant',\n",
    "       'Event Space', 'Falafel Restaurant', 'Farm', 'Farmers Market',\n",
    "       'Fast Food Restaurant', 'Field', 'Filipino Restaurant',\n",
    "       'Fireworks Store', 'Fish & Chips Shop', 'Fish Market',\n",
    "       'Flea Market', 'Flower Shop', 'Food', 'Food & Drink Shop',\n",
    "       'Food Court', 'Food Truck', 'Fountain', 'French Restaurant',\n",
    "       'Fried Chicken Joint', 'Frozen Yogurt Shop',\n",
    "       'Fruit & Vegetable Store', 'Furniture / Home Store', 'Gaming Cafe',\n",
    "       'Garden', 'Garden Center', 'Gas Station', 'Gastropub', 'Gay Bar',\n",
    "       'General Entertainment', 'German Restaurant', 'Gift Shop',\n",
    "       'Golf Course', 'Gourmet Shop', 'Greek Restaurant', 'Grocery Store',\n",
    "       'Gym', 'Gym / Fitness Center', 'Gym Pool', 'Hakka Restaurant',\n",
    "       'Halal Restaurant', 'Harbor / Marina', 'Hardware Store',\n",
    "       'Hawaiian Restaurant', 'Health & Beauty Service',\n",
    "       'Health Food Store', 'Historic Site', 'History Museum',\n",
    "       'Hobby Shop', 'Hockey Arena', 'Home Service', 'Hookah Bar',\n",
    "       'Hostel', 'Hot Dog Joint', 'Hotel', 'Hotel Bar',\n",
    "       'Hotpot Restaurant', 'Housing Development', 'IT Services',\n",
    "       'Ice Cream Shop', 'Indian Chinese Restaurant', 'Indian Restaurant',\n",
    "       'Indie Movie Theater', 'Indie Theater', 'Indonesian Restaurant',\n",
    "       'Intersection', 'Italian Restaurant', 'Japanese Restaurant',\n",
    "       'Jazz Club', 'Jewelry Store', 'Jewish Restaurant', 'Juice Bar',\n",
    "       'Karaoke Bar', 'Kids Store', 'Kitchen Supply Store',\n",
    "       'Korean Restaurant', 'Lake', 'Latin American Restaurant',\n",
    "       'Laundry Service', 'Light Rail Station', 'Lingerie Store',\n",
    "       'Liquor Store', 'Lounge', 'Mac & Cheese Joint', 'Malay Restaurant',\n",
    "       'Market', 'Martial Arts Dojo', 'Massage Studio', 'Mattress Store',\n",
    "       'Mediterranean Restaurant', \"Men's Store\", 'Metro Station',\n",
    "       'Mexican Restaurant', 'Middle Eastern Restaurant',\n",
    "       'Miscellaneous Shop', 'Mobile Phone Shop',\n",
    "       'Modern European Restaurant', 'Monument / Landmark',\n",
    "       'Moroccan Restaurant', 'Motorcycle Shop', 'Movie Theater',\n",
    "       'Museum', 'Music School', 'Music Store', 'Music Venue',\n",
    "       'Nail Salon','New American Restaurant',\n",
    "       'Nightclub', 'Noodle House', 'Office', 'Optical Shop',\n",
    "       'Organic Grocery', 'Other Great Outdoors', 'Other Repair Shop',\n",
    "       'Outdoors & Recreation', 'Pakistani Restaurant',\n",
    "       'Paper / Office Supplies Store', 'Park', 'Pastry Shop',\n",
    "       'Performing Arts Venue', 'Persian Restaurant', 'Pet Store',\n",
    "       'Pharmacy', 'Photography Lab', 'Pide Place', 'Pie Shop',\n",
    "       'Pilates Studio', 'Pizza Place', 'Playground', 'Plaza',\n",
    "       'Poke Place', 'Polish Restaurant', 'Pool', 'Pool Hall',\n",
    "       'Portuguese Restaurant', 'Poutine Place', 'Print Shop', 'Pub',\n",
    "       'Ramen Restaurant', 'Record Shop', 'Recreation Center',\n",
    "       'Rental Car Location', 'Residential Building (Apartment / Condo)',\n",
    "       'Restaurant', 'River', 'Road', 'Rock Climbing Spot', 'Rock Club',\n",
    "       'Roof Deck', 'Sake Bar', 'Salad Place', 'Salon / Barbershop',\n",
    "       'Sandwich Place', 'Scenic Lookout', 'School', 'Sculpture Garden',\n",
    "       'Seafood Restaurant', 'Shanghai Restaurant', 'Shoe Store',\n",
    "       'Shop & Service', 'Shopping Mall', 'Skate Park', 'Skating Rink',\n",
    "       'Ski Area', 'Ski Chalet', 'Smoke Shop', 'Smoothie Shop',\n",
    "       'Snack Place', 'Soccer Field', 'Soccer Stadium', 'Social Club',\n",
    "       'Soup Place', 'South American Restaurant',\n",
    "       'Southern / Soul Food Restaurant', 'Souvlaki Shop', 'Spa',\n",
    "       'Spanish Restaurant', 'Speakeasy', 'Sporting Goods Shop',\n",
    "       'Sports Bar', 'Sports Club', 'Sri Lankan Restaurant',\n",
    "       'Stationery Store', 'Steakhouse', 'Storage Facility', 'Street Art',\n",
    "       'Supermarket', 'Supplement Shop', 'Sushi Restaurant', 'Taco Place',\n",
    "       'Tailor Shop', 'Taiwanese Restaurant', 'Tanning Salon',\n",
    "       'Tapas Restaurant', 'Tea Room', 'Tech Startup', 'Tennis Court',\n",
    "       'Thai Restaurant', 'Theater', 'Theme Restaurant',\n",
    "       'Thrift / Vintage Store', 'Tibetan Restaurant', 'Toy / Game Store',\n",
    "       'Track', 'Trail', 'Train Station', 'Tree', 'Turkish Restaurant',\n",
    "       'Udon Restaurant', 'University', 'Vegetarian / Vegan Restaurant',\n",
    "       'Video Game Store', 'Video Store', 'Vietnamese Restaurant',\n",
    "       'Warehouse Store', 'Waste Facility', 'Whisky Bar', 'Wine Bar',\n",
    "       'Wine Shop', 'Wings Joint', \"Women's Store\", 'Yoga Studio', 'Zoo']]\n",
    "# Toronto_onehot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_grouped = Toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "Toronto_grouped.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_top_venues = 5\n",
    "\n",
    "# for hood in Toronto_grouped['Neighborhood']:\n",
    "# #     print(\"----\"+hood+\"----\")\n",
    "#     temp = Toronto_grouped[Toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "#     temp.columns = ['venue','freq']\n",
    "#     temp = temp.iloc[1:]\n",
    "#     temp['freq'] = temp['freq'].astype(float)\n",
    "#     temp = temp.round({'freq': 2})\n",
    "#     print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = Toronto_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(Toronto_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusters = 8\n",
    "\n",
    "Toronto_grouped_clustering = Toronto_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Toronto_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.drop('Cluster Labels',axis=1,inplace= True)\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "Toronto_merged = data_frame\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "Toronto_merged = Toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "Toronto_merged.head() # check the last columns!\n",
    "Toronto_merged_cluster=Toronto_merged.groupby('Cluster Labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.dropna(inplace=True)\n",
    "Toronto_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(Toronto_merged['Latitude'], Toronto_merged['Longitude'], Toronto_merged['Neighborhood'], Toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster)-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster)-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examin Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 0, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 1, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 2, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 3, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 4, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 5, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 6, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toronto_merged.loc[Toronto_merged['Cluster Labels'] == 7, Toronto_merged.columns[[1] + list(range(5, Toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
